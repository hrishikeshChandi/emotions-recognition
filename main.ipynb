{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20df874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = f\"{path}/train\"\n",
    "test_dir = f\"{path}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(\n",
    "    root=train_dir, transform=data_transforms, target_transform=None\n",
    ")\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=test_dir, transform=test_transform, target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_data_loader = DataLoader(test_data, batch_size=32, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_data[0]\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title(class_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b2(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.features.parameters():\n",
    "    layer.requires_grad = False\n",
    "\n",
    "for layer in list(model.features.parameters())[:-7]:\n",
    "    layer.requires_grad = True\n",
    "\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.6, inplace=True),\n",
    "    nn.Linear(in_features=1408, out_features=len(class_names), bias=True),\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a043d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 224, 224)).to(device)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights = torch.tensor(\n",
    "    [1.02, 9.37, 0.99, 0.57, 0.82, 0.85, 1.28], dtype=torch.float32\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_fn = nn.CrossEntropyLoss(weight=train_weights)\n",
    "test_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\"params\": model.features.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": model.classifier.parameters(), \"lr\": 5e-4},\n",
    "    ],\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=5, mode=\"min\", factor=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    return correct / len(y_true) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"./emotions_results (b2_5e-4)\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "    print(\"created\")\n",
    "\n",
    "with open(f\"{results_path}/class_names.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 3\n",
    "early_stop = 0\n",
    "best_loss = None\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"{results_path}/runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    train_acc, train_loss = 0, 0\n",
    "    model.train()\n",
    "    for batch, (X, y) in tqdm(\n",
    "        enumerate(train_data_loader),\n",
    "        leave=False,\n",
    "        total=len(train_data_loader),\n",
    "        desc=f\"Training Epoch {epoch}\",\n",
    "    ):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = train_loss_fn(logits, y)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc_fn(y, logits.argmax(dim=1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_data_loader)\n",
    "    train_acc /= len(train_data_loader)\n",
    "\n",
    "    model.eval()\n",
    "    test_acc, test_loss = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in tqdm(\n",
    "            enumerate(test_data_loader),\n",
    "            leave=False,\n",
    "            total=len(test_data_loader),\n",
    "            desc=f\"Testing Epoch {epoch}\",\n",
    "        ):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            test_loss += test_loss_fn(logits, y).item()\n",
    "            test_acc += acc_fn(y, logits.argmax(dim=1))\n",
    "        test_acc /= len(test_data_loader)\n",
    "        test_loss /= len(test_data_loader)\n",
    "\n",
    "    writer.add_scalars(\n",
    "        main_tag=\"Loss\",\n",
    "        tag_scalar_dict={\"train_loss\": train_loss, \"test_loss\": test_loss},\n",
    "        global_step=epoch,\n",
    "    )\n",
    "    writer.add_scalars(\n",
    "        main_tag=\"Accuracy\",\n",
    "        tag_scalar_dict={\"train_acc\": train_acc, \"test_acc\": test_acc},\n",
    "        global_step=epoch,\n",
    "    )\n",
    "    writer.add_scalar(\n",
    "        tag=\"Learning Rate\",\n",
    "        scalar_value=optimizer.param_groups[0][\"lr\"],\n",
    "        global_step=epoch,\n",
    "    )\n",
    "\n",
    "    info = f\"Epoch: {epoch} | Train acc: {train_acc:.5f} | Train loss: {train_loss:.5f} | Test acc: {test_acc:.5f} | Test loss: {test_loss:.5f}\"\n",
    "\n",
    "    with open(f\"{results_path}/training_info.txt\", \"a\") as f:\n",
    "        f.write(info + \"\\n\")\n",
    "\n",
    "    print(info)\n",
    "\n",
    "    old_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    scheduler.step(test_loss)\n",
    "    new_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    if new_lr < old_lr:\n",
    "        print(\n",
    "            f\"Learning rate is reduced from: {old_lr} -> {new_lr} after epoch: {epoch}\"\n",
    "        )\n",
    "\n",
    "    if best_loss is None:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model, f\"{results_path}/model.pth\")\n",
    "        print(f\"Best model saved after epoch: {epoch}\")\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model, f\"{results_path}/model.pth\")\n",
    "        print(f\"Best model saved after epoch: {epoch}\")\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop == patience:\n",
    "            print(f\"Early stopping after epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = torch.load(f\"{results_path}/model.pth\", weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "test_loss, test_acc = 0, 0\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for batch, (X, y) in tqdm(\n",
    "        enumerate(test_data_loader),\n",
    "        leave=False,\n",
    "        total=len(test_data_loader),\n",
    "        desc=\"Testing\",\n",
    "    ):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        test_loss += test_loss_fn(logits, y).item()\n",
    "        test_acc += acc_fn(y, logits.argmax(dim=1))\n",
    "        y_pred = logits.argmax(dim=1)\n",
    "        test_preds.append(y_pred.cpu())\n",
    "\n",
    "    test_loss /= len(test_data_loader)\n",
    "    test_acc /= len(test_data_loader)\n",
    "\n",
    "test_preds = torch.cat(test_preds)\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torchmetrics import ConfusionMatrix\n",
    "except:\n",
    "    !pip install torchmetrics\n",
    "    from torchmetrics import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n",
    "conf_mat = cm(test_preds, torch.Tensor(test_data.targets).type(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=conf_mat.numpy(), class_names=class_names, figsize=(7, 7)\n",
    ")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.savefig(f\"{results_path}/confusion_matrix.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "torch.save(model, f\"{results_path}/cpu_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
